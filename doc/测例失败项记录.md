# 已知及偶然性的测例失败项待办列表

- [ ] ipc 之后执行 proc 测例概率因 page fault 终止

该现象共出现过两次，分别位于 exit 与 fork 测例，其中 fork 测例中产生的 page fault 位于 rq_insert 的空指针成员偏移访问，对应变量未知。

重复五六次尝试复现，复现无果，故在此记录。

- [ ] ls 操作概率导致崩溃重启

原始描述：无

最新描述：修复 vfs 问题时发现 vfs 较为脆弱，几乎每一次因漏洞而失败的 fs 操作都会导致在这之后的 fs 操作失败，包括但不限于崩溃重启、并发读写原子性测试失败、page fault 等等。经过相关修复后该项错误可能一并解决，已长期未触发该现象，但暂时无法确定。

- [ ] 执行 fs 测例后执行 proc 测例概率导致崩溃重启

该现象首次出现的场景为：疯狂执行 fs 测例并全数通过，在这之后紧接着执行 proc 测例系统崩溃重启后，在这之后继续执行 proc 测例依旧崩溃重启，在这之后等待若干秒后再执行 proc 测例运行正常。

重新仿真模拟上述过程，未能复现。

情景补充：在 v2.3.0.beta.1 版本下启动仿真常规速度先执行 fs 测例再执行 proc，出现崩溃重启现象。

- [ ] 非实时调度队列结构失效导致断言失败

具体指代 kernel/sched.c:is_rq_empty 中的关于队列判空的断言，该错误在多个高并发场景下均曾出现。

- [x] 内存过大时系统启动失败

当内存大小大于等于 1004.5 MiB 时，AHCI Controller 异常，报错 `error: ahci mode not supported`，于 bootloader 加载内核失败导致系统启动失败。

其中 1004 MiB 启动成功，为最大可启动内存。

调试结果：ahci controller 的 mmio 在本实现中等值映射在 0xfebf1000，当达到 1005 MiB 后该线性地址将提前被映射在内核空间，导致 mmio 的映射失败，随后对设备的访问实际落在 ram 上而非设备内存空间。

解决方案：

**方案一**

在 1MiB\~3GiB 之间随便找个线性地址映射到设备地址。

**方案二**

若已经映射，替换原页表项完成设备配置，在内核加载完成后跳入内核前回滚该操作。

注意事项：kernel 里完成的 ahci 设备初始化也是一样，记得要改。

最终解决方案：

1. loader 采取添加 vma alloc 通过分配空闲线性地址处理
2. kernel 由于在共享页表搜索空闲实现，无需更改，但对于大内存（高于 1G）需额外限制 buddy 分配到内核态的物理内存
3. 引入 ioremap/iounmap 实现一般的设备 mmio

- [ ] dentry 死锁 / hd\_service 死锁

反复运行 proc 测例约一个半小时后，Execve.WaitAfterExecve 测试项的 33、36 和 38 号进程在 /bin/execve 的 bin 目录项上死锁，其中 33、36 号进程在 kern\_execve 下打开文件下层的 get\_dentry 处死锁，同时 38 号进程位于 hd\_rdwt\_sched 的 wait\_event(&hdque)，获得锁者为 38 号进程。

其中 38 号进程在 kern\_execve /bin/execve 下的  vfs\_put\_dentry bin 下的 vfs\_sync\_inode 下直到 wait\_event(&hdque)，该进程在 wait\_event(&hdque) 主动 sched\_yield 前被调度走且始终未被唤醒。对应的，此时 hd\_service 进程正在 ksem\_wait(&hdque_full, 1)。

备注：该问题暂时出现次数 2，最后一次出现时机在提交 e28c6e4。

- [ ] slab 分配的对象无法释放

反复随机运行测例，概率在 ipc 测例 的 MsgQueueSend.WaitUntil 测试项中的子进程 msgctl 中的 pop_front_msg_node 中触发。

具体地，pop_front_msg_node 中的 phy\_kfree 从 slab 中尝试释放对象，在 slab\_free 中的查找对象循环中始终无法在 cache 的 partial/full 的 slab 链中找到对应对象，继而无限重复尝试失败。

在这过程中测例仅父子进程，且父进程处于 wait 睡眠状态等待子进程结束。

情景补充：在以上情景的复现中再次调试，发现待释放对象 0xc4f70040 位于 cache 的 empty 链的第 2 个 slab 0xc4f70000 中，对应 slab 位图标记和总对象数均为 0，结构未损坏，可猜测该地址被二次释放。

警告：若以上提及的二次释放成立，则原使用处可能使用了已经释放的内存，这将导致不可预期的错误。

- [x] fs 相关操作的耗时随运行时长增加而显著增加

反复随机运行测例一小时及以上，fs 测例运行耗时从百毫秒级暴涨至十秒级，对于约一小时处的运行结果，耗时翻了将近七十倍。

严格来说这并非测例 NG，但是考虑到问题过于严重，不得不将其视为需要修复/优化的紧急待办项。

解决方案：不需要解决，出现该问题的原因是原测例在 /tmp 创建文件但是并不删除，越来越慢纯属是 tmp 文件太多了，在 fat32 impl 中找文件找空位啥的操作耗时变长。在 shell 每次执行完测例里手动清 /tmp 再跑一小时随机测例，得到 fs 的运行时长始终稳定在 \~180ms，可以得到验证。

- [x] 增加 ACPI SDST 设备树遍历枚举后系统异常崩溃

扫描动作产生于 kernel\_main 阶段，使用的栈为 kernel.asm 中 .bss 段中给出的 4KB 空间。

递归遍历导致栈指针下溢覆写了相邻的 irq handler 表，导致在覆写之后的时钟中断中跳转到了无效的 handler 从而引发 page fault 崩溃。

解决方案：kernel\_main 阶段切换栈区，一方面调整栈的容量至 1MB，另一方面在栈的上下边界建立守卫页以便在类似异常发生时快速定位。

- [x] 真机 acpi 初始化在 2K 内存分配的内存块页面状态异常导致释放处断言失败

我得说这并不偶然而极其确定，你甚至可以百分百复现这个问题，仿真能过大概是运气好没什么地方用到了 2K 分配而 PASS 了，事实上这个问题要远比描述的大得多。

目前的 slab 分配是由单个物理页建立 slab，该物理页同时容纳 slab 结构与关联的对象池。

在之前的某个版本中，李荣处理了 slab 对象池未对齐而导致的异常，但是当前的错误显然表明的当时处理的不完善。

该错误的概括表述为“对象池及相关状态的不一致性”，相关描述如下：

1. 分配一页作为 slab 页，页首初始化 slab 结构，其后空间依据对象大小幂二对齐取为对象池基址
2. 因对齐而损失的空间在 slab 方面记录为保留的已分配对象，影响位图状态，已分配对象个数，对象索引
3. 因对齐而损失的空间在 cache 方面记录为原始便不用于对象分配的空间，影响最大对象数，slab 的对象池基址
4. 分配并取对象地址的方法为对象池基址偏移对象索引与对象大小之积

附加陈述有下：

1. 从 cache 分配而所有 slab 持有的空闲对象不足时创建新 slab，该新 slab 考虑对齐问题初始化已分配对象个数与位图状态，并置入 PARTIAL 链
2. slab 的移动操作发生在任意对象的分配/释放之后

引发的错误有下：

1. 因空间损失的存在，在 2、3 不一致性的条件下，任意移入 EMPTY 链的 slab 均为伪 EMPTY，其位图状态与已分配对象个数的属性处于损坏状态
2. 因 2、3 不一致性的存在，任意移入 FULL 链的 slab 均为伪 FULL，其仍剩余 1 空闲对象可分配
3. 在 2、3 不一致性的前提下，对象索引在 4 的计算方式下造成分配出的对象地址的上溢（此处发现的问题）

其中，由于附加描述的存在，错误 3 的产生具有必要条件“分配大小为 2K”。此时尽管 slab 的已分配对象个数已达到最大对象数，但其仍位于 buddy 的 PARTIAL 链，故将始终执行为错误 3 的路径；而对于 2K 以下的对象分配，首次分配为“有效”分配，同时附加描述 2 使得对象分配达到伪上限移入 FULL 链，此时执行为错误路径 2，但另一方面，该错误路径也使得其免于对象地址上溢，从而表现出“只有 2K 分配会报错，而其他小内存分配运行非常良好”的假象。

解决方案：取当前 slab 的状态维护为主，将因对齐而损失的空间记录为保留的已分配对象，同时对象池基址还原为页面基址以确保一致性。

- [ ] 随机测例运行 2.5hr 后 fs read 测例因 hd_service 断言失败而失败

基准代码 a93db95，错误日志如下：

```plain
kernel/hd.c:hd_rdwt:262: fatal: assertion failed: nr_sector < part->size
backtrace of process [pid=2]:
    => 0xbfffefcc (0xc0603474)
    => 0xbfffeffc (0)
[#GP General Protection] eip=0xc06062a0 eflags=0x1013 cs=0x5 err_code=0 from "hd_service" [pid=2]
2025-03-16 00:27:58 [#PF Page Fault] eip=0xc060c66e eflags=0x1282 cs=0x8 err_code=0 from "hd_service" [pid=2]
```

表现为因磁盘读写越界分区大小引发的连锁错误。

- [x] 某远古机器上的超高频率 Spurious IRQ 7 导致内核无法正常运行

相关情况在文档典籍中亦有记载，但很显然其原因并没有被记录。

直接现象：如题。

现象细节：一个最低优先级的 Spurious IRQ 7 总是伴随着一次最高优先级的时钟中断触发，在同一批次的中断请求的最后被处理，若直至下一次时钟中断到来前 Spurious IRQ 7 仍为处理（如本批次中断服务耗时过长相对于时钟频率超时了），则表现出 Spurious IRQ 7 未触发的假象。

> 这个狗细节真是历经九九八十一难排查了若干个设备打了无数断点插了无数输出插了无数桩反复验证才确定下来的，来之不易，且看且珍惜。

问题分析：

1. 首先，肯定是自身不够硬，如果 miniOS 高度并发安全且中断机制良好那么即使 Spurious IRQ 7 及相关处理例程再频繁也不会有影响。当然，如果做的太好可能反而查不出这个问题了。
2. 自行翻阅 PIC 8259A 手册，可知 PIC 在竞态条件下可能因硬件中断发生但又在 PIC 转发到 CPU 之前取消（比如信号线噪声，比如 EOI 发送时机不对）而产生 Spurious IRQ，该 IRQ 总是为最低优先级的 IRQ 7（级联从片上就是对应 15 23 ...）。
3. 原系统中断例程中实现的 spurious_irq 跟本例中所遇到的 Spurious IRQ 7 不是同一个概念，系统中的例程对应的是软件层的未注册 handler 的任意 IRQ，而本例中 Spurious IRQ 7 特指硬件层 PIC 语义下的虚假 IRQ；前者可能是真实硬件 IRQ 而只是无法被系统处理（没处理方法），也可能是真正的不存在的 IRQ，而后者一定是一个假 IRQ 触发；对于前者，可通过 PIC isr 寄存器判断对应中断号是否被响应并在 in-service 状态中置位，若未置位则为伪 IRQ。
4. 细看 miniOS 原中断处理的全部中断部分，可知原实现中刚进入中断例程就粗暴地发 EOI 表示中断服务已完成，这是违反手册建议的（你应当在服务处理完成后发送该信号）。
5. ……

实际上也分析不出来啥，一番倒腾能判断出来的只有原实现中的各种疏漏，各种大坑，故而首先根据手册将 PIC 和中断处理方法全部重写，重写后的处理过程已与 FreeBSD 的整体过程对比，不能说完全一致，只能说各个处理节点 99.99\% 是重合的，那么可以基本判断重写后的中断处理没大问题。

然后你会发现问题并没有解决。

然后你可能会说：欸！我同一台机子 Ubuntu 就没问题凭什么你 miniOS 就有问题呢？它能正常跑而且查日志也没有 Spurious IRQ 那怎么可能是硬件问题，不就是你代码写的一坨屎吗？！

说的好，那我们 dmesg 一下再来分析下两个系统的硬件差异。

可以发现 Ubuntu 自解压 boot 时就已经建立先进的 APIC 了，至于 PIC，弔都没弔一下；而我们粗制滥造的 miniOS 由于以懒惰和个人精力有限为主因的各种因素只能使用历史传承不知道哪个旮旯抄来的 PIC 中断处理。

你得知道 APIC 和 PIC 虽然都在 ISA 总线上但完全是两个不同的设备，甚至于对于 Spurious IRQ 二者都有显著不同——APIC 为 Spurious IRQ 分配一个独立的 IRQ 号，而引脚有限的 PIC 只能复用最低优先级的 IRQ 7 和 isr 寄存器来表达一个 Spurious IRQ。

用的都不是一个中断控制器，变量不控制，怎么能验证硬件没问题，代码有问题呢？！

所以换了台机子跑，很好，直捣黄龙（其实又有一个新的问题，也就是后一个 BUG），PASS 了。

一锤定音：上古机器的 PIC 坏了。

> 关于 PIC 为什么选择 IRQ 7 作为 Spurious IRQ：
>
> 默认情况下，IRQ 0 优先级最高，IRQ 7 优先级最低，令 Spurious IRQ 在最后被处理能够使影响最小化。
>
> 想象一下在如果在一批中断中你的 Spurious IRQ 以高优先级的姿态打断了当前中断例程嵌套处理（实际上到这里已经很糟糕了），而你为 Spurious IRQ 注册的中断例程又好死不死地无脑 EOI 了（EOI 命令的默认行为是重置 isr 中最高优先级的一个中断），那完了，被打断的那位正经硬件中断例程被你迫害了提前告知 PIC 人家已经处理完成（Spurious IRQ 在 isr 是不置位的），等 Spurious IRQ 处理完成，假设现在不立马崩，那么上一个被打断的例程结束后又会 EOI 一次把它的前辈给迫害了（如果它也是高优先级抢断嵌套处理的话），如此循环往复，除非气运之子，必挂也。

- [x] UART 回环模式收发检测收到的数据与发送的数据不一致

将远古机器 A 作为调试机，常规机器 B 作为测试机，二者串口线连接 COM1，B 输出的 loader 的日志能够正常被 A 接受。

在 A 上配置完 COM1 后使用 cat 将串口输出重定向至本地文件，维持该状态，当 B 从 loader 进入 kernel 并进行早期初始化后 uart 初始化因在 loopback 模式下的收发测试不通过而断言失败终止。

细节如下：

1. 检查状态寄存器，在写后读之后 Data Ready 仍置位，这表示在发送测试数据前有更多的数据已经到来，读出的是之前的数据
2. 进一步验证，发现开始初始化、配置完成、进入回环模式的整个过程中持续有数据传输，在进入回环模式后未接收到更多数据
3. 进一步验证，发现过程中传输的数据正好是 loader 输出的日志，但这是不对的，loader 的 uart 早就不是回环模式，不应该读取到发送出去的数据
4. 进一步验证，拔掉与新调试机通信的串口线，以上问题均不出现
5. 进一步验证，在 A 上使用 minicom 而不是 cat 通信，以上问题均不出现

其中设备接收到的 loader 阶段输出的日志有显著特征，为 loader 日志全部输出的前若干字节和最后若干字节，中间的大部分输出均未被本设备接收，但同时 A 端能够完整地接收到全部数据。

调换 A、B 机器的角色，此问题不会出现。

解决方案：进入回环模式后在测试前读出所有到达的数据后再进行发收测试。

注意：此例产生的现象不合理，且在不同机器下不能稳定复现，而开源 OS 的相关部分亦无相关处理逻辑，无法确定是 cat 有问题还是两台机子中谁的串口有问题，故该解决方案为针对性措施，不具有必要性。
